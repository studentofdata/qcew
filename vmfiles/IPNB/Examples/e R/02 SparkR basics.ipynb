{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Spark basics\n",
    "\n",
    "This notebook shows a few very simple steps with [Spark R](https://spark.apache.org/docs/latest/sparkr.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'SparkR'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cov, filter, lag, na.omit, predict, sd, var\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    colnames, colnames<-, intersect, rank, rbind, sample, subset,\n",
      "    summary, table, transform\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the SparkR package. \n",
    "# It will likely show a few warnings about functions that the package overrides\n",
    "library(SparkR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a new Spark Context\n"
     ]
    }
   ],
   "source": [
    "# In the IRkernel we do not have an automatically created Spark Context, as in Python & Scala. \n",
    "# We need to initialize the kernel to fetch one. That takes a few moments.\n",
    "sc <- sparkR.init( \"local[*]\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Once we have it, we can also obtain an SQL context\n",
    "sqlContext <- sparkRSQL.init(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "In FUN(X[[i]], ...): Use Sepal_Length instead of Sepal.Length  as column nameWarning message:\n",
      "In FUN(X[[i]], ...): Use Sepal_Width instead of Sepal.Width  as column nameWarning message:\n",
      "In FUN(X[[i]], ...): Use Petal_Length instead of Petal.Length  as column nameWarning message:\n",
      "In FUN(X[[i]], ...): Use Petal_Width instead of Petal.Width  as column name"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Sepal_Length</th><th scope=col>Sepal_Width</th><th scope=col>Petal_Length</th><th scope=col>Petal_Width</th><th scope=col>Species</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>5.4</td><td>3.9</td><td>1.7</td><td>0.4</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>4.6</td><td>3.4</td><td>1.4</td><td>0.3</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>5.7</td><td>4.4</td><td>1.5</td><td>0.4</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>5.4</td><td>3.9</td><td>1.3</td><td>0.4</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.3</td><td>setosa</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>5.7</td><td>3.8</td><td>1.7</td><td>0.3</td><td>setosa</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & Sepal_Length & Sepal_Width & Petal_Length & Petal_Width & Species\\\\\n",
       "\\hline\n",
       "\t1 & 5.4 & 3.9 & 1.7 & 0.4 & setosa\\\\\n",
       "\t2 & 4.6 & 3.4 & 1.4 & 0.3 & setosa\\\\\n",
       "\t3 & 5.7 & 4.4 & 1.5 & 0.4 & setosa\\\\\n",
       "\t4 & 5.4 & 3.9 & 1.3 & 0.4 & setosa\\\\\n",
       "\t5 & 5.1 & 3.5 & 1.4 & 0.3 & setosa\\\\\n",
       "\t6 & 5.7 & 3.8 & 1.7 & 0.3 & setosa\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n",
       "1          5.4         3.9          1.7         0.4  setosa\n",
       "2          4.6         3.4          1.4         0.3  setosa\n",
       "3          5.7         4.4          1.5         0.4  setosa\n",
       "4          5.4         3.9          1.3         0.4  setosa\n",
       "5          5.1         3.5          1.4         0.3  setosa\n",
       "6          5.7         3.8          1.7         0.3  setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do something to prove it works\n",
    "\n",
    "# Load one of the standard datasets that come pre-packaged with R\n",
    "data(iris)\n",
    "\n",
    "# Turn the dataset into an SparkR DataFrame\n",
    "df <- createDataFrame(sqlContext, iris)\n",
    "\n",
    "# Inspect it\n",
    "head( filter(df, df$Petal_Width > 0.2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sc is an existing SparkContext.\n",
    "# hiveContext <- sparkRHive.init(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
